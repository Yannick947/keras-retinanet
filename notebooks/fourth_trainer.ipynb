{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"fourth_trainer.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1ZAms18hXd_ECNLGA7E6iyJQl_GViTcmJ","authorship_tag":"ABX9TyMFxyfZYuUNjdELV0GiNX0f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587362575131,"user_tz":-120,"elapsed":3547,"user":{"displayName":"horst hammer","photoUrl":"","userId":"16387219538505432860"}},"id":"spDiWJ97I0vZ","outputId":"e2274b26-0132-4d24-cce6-34f240009a68","colab":{"base_uri":"https://localhost:8080/","height":319}},"source":["%cd ../../../../../../\n","!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/\n","Mon Apr 20 06:02:53 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j5KSeQKwuZYB","outputId":"34225434-375a-4c88-8ca9-a671f7a3f6e1","executionInfo":{"status":"ok","timestamp":1587362663513,"user_tz":-120,"elapsed":91914,"user":{"displayName":"horst hammer","photoUrl":"","userId":"16387219538505432860"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install gdown\n","!pip install tensorflow-gpu --user\n","!pip install --upgrade keras"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.38.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.4.5.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n","Collecting tensorflow-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n","\u001b[K     |████████████████████████████████| 421.8MB 31kB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 34.3MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.28.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 34.5MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.7.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (46.1.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.10.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2020.4.5.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=b7ebc4992819bcb411587b642658aaed9d01024011a41648389a7a2e9351cd9c\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow-gpu\n","\u001b[33m  WARNING: The script tensorboard is installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n","\u001b[33m  WARNING: The scripts estimator_ckpt_converter, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n","Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n","Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KW6Cre21sZqg","outputId":"27d1c9b1-e28b-4d2a-a55f-d2ec6ceaa639","executionInfo":{"status":"ok","timestamp":1587362732667,"user_tz":-120,"elapsed":161057,"user":{"displayName":"horst hammer","photoUrl":"","userId":"16387219538505432860"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!git clone https://Yannick947:Amadeusieben7@github.com/Yannick947/keras-retinanet.git\n","%cd keras-retinanet/\n","!pip install .\n","!python setup.py build_ext --inplace\n","%cd ../content/sample_data/\n","!git clone https://github.com/Yannick947/WiderPerson.git -b master --single-branch\n","%cd ../../../"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'keras-retinanet'...\n","remote: Enumerating objects: 5893, done.\u001b[K\n","remote: Counting objects: 100% (5893/5893), done.\u001b[K\n","remote: Compressing objects: 100% (1989/1989), done.\u001b[K\n","remote: Total 5893 (delta 3720), reused 5868 (delta 3695), pack-reused 0\u001b[K\n","Receiving objects: 100% (5893/5893), 46.11 MiB | 17.43 MiB/s, done.\n","Resolving deltas: 100% (3720/3720), done.\n","Checking out files: 100% (305/305), done.\n","/keras-retinanet\n","Processing /keras-retinanet\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-retinanet==0.5.1) (2.3.1)\n","Collecting keras-resnet==0.1.0\n","  Downloading https://files.pythonhosted.org/packages/05/46/ad0b2d1a05d9497bd80c98a2c3f4d8be38a4601ace69af72814f5fafd851/keras-resnet-0.1.0.tar.gz\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras-retinanet==0.5.1) (1.12.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-retinanet==0.5.1) (1.4.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from keras-retinanet==0.5.1) (0.29.16)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from keras-retinanet==0.5.1) (7.0.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from keras-retinanet==0.5.1) (4.1.2.30)\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from keras-retinanet==0.5.1) (3.38.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-retinanet==0.5.1) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-retinanet==0.5.1) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-retinanet==0.5.1) (3.13)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-retinanet==0.5.1) (1.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-retinanet==0.5.1) (1.18.2)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->keras-retinanet==0.5.1) (2.4.0)\n","Building wheels for collected packages: keras-retinanet, keras-resnet\n","  Building wheel for keras-retinanet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-retinanet: filename=keras_retinanet-0.5.1-cp36-cp36m-linux_x86_64.whl size=178330 sha256=bee74457b33e8b15b848ef04973c4e731a19020c385f60e8507edc17dbad34a7\n","  Stored in directory: /root/.cache/pip/wheels/d8/c4/37/e6e27e600dc64bcb9272bd238220c867e3addca32614dcccb0\n","  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-resnet: filename=keras_resnet-0.1.0-py2.py3-none-any.whl size=13346 sha256=c4ebfc4c617092dc8b9720b2113bf49bc455708be48ac2cbf938dac790dd6e00\n","  Stored in directory: /root/.cache/pip/wheels/80/dd/ac/842235b63dddac12faa4b48ebe58b8944e8c2e57c2e38dddb6\n","Successfully built keras-retinanet keras-resnet\n","Installing collected packages: keras-resnet, keras-retinanet\n","Successfully installed keras-resnet-0.1.0 keras-retinanet-0.5.1\n","running build_ext\n","skipping 'keras_retinanet/utils/compute_overlap.c' Cython extension (up-to-date)\n","building 'keras_retinanet.utils.compute_overlap' extension\n","creating build\n","creating build/temp.linux-x86_64-3.6\n","creating build/temp.linux-x86_64-3.6/keras_retinanet\n","creating build/temp.linux-x86_64-3.6/keras_retinanet/utils\n","x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -c keras_retinanet/utils/compute_overlap.c -o build/temp.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.o\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[Kkeras_retinanet/utils/compute_overlap.c:598\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n"," #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n","  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n","creating build/lib.linux-x86_64-3.6\n","creating build/lib.linux-x86_64-3.6/keras_retinanet\n","creating build/lib.linux-x86_64-3.6/keras_retinanet/utils\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.o -o build/lib.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.cpython-36m-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.cpython-36m-x86_64-linux-gnu.so -> keras_retinanet/utils\n","/content/sample_data\n","Cloning into 'WiderPerson'...\n","remote: Enumerating objects: 13396, done.\u001b[K\n","remote: Total 13396 (delta 0), reused 0 (delta 0), pack-reused 13396\n","Receiving objects: 100% (13396/13396), 964.79 MiB | 35.29 MiB/s, done.\n","Checking out files: 100% (13386/13386), done.\n","/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gGcaSEpMwxB4","colab_type":"code","outputId":"0e0d48ba-800d-49d1-9b8c-1f845e10ff2e","executionInfo":{"status":"ok","timestamp":1587362735290,"user_tz":-120,"elapsed":163668,"user":{"displayName":"horst hammer","photoUrl":"","userId":"16387219538505432860"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["bin\t\t\t\t\t   lib\t  srv\n","boot\t\t\t\t\t   lib32  swift\n","content\t\t\t\t\t   lib64  sys\n","datalab\t\t\t\t\t   media  tensorflow-1.15.2\n","dev\t\t\t\t\t   mnt\t  tmp\n","dlib-19.18.0-cp27-cp27mu-linux_x86_64.whl  opt\t  tools\n","dlib-19.18.0-cp36-cp36m-linux_x86_64.whl   proc   usr\n","etc\t\t\t\t\t   root   var\n","home\t\t\t\t\t   run\n","keras-retinanet\t\t\t\t   sbin\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"33KexW3M7xhZ","colab_type":"code","outputId":"f0bfd76b-9502-45c3-8da5-ac6c7149574d","executionInfo":{"status":"ok","timestamp":1587362742465,"user_tz":-120,"elapsed":170830,"user":{"displayName":"horst hammer","photoUrl":"","userId":"16387219538505432860"}},"colab":{"base_uri":"https://localhost:8080/","height":252}},"source":["#quickfix error in callbacks of keras, pullrequest is already open in github\n","#later versions of tensorflow and keras should contain this fix (if error Attribute: \n","# 'Error: 'Model' object has no attribute '_get_distribution_strategy' during training appears, \n","# The %cd command must be changed to the new directory of the callback.py file because\n","# the directory changes from time to time. \n","\n","%cd ../../../../../\n","from google.colab import files\n","import shutil\n","%cd /root/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/\n","# files.download('callbacks.py')\n","!rm callbacks.py\n","shutil.copyfile('/content/drive/My Drive/person_detection/utils/callbacks.py', \n","            './callbacks.py')\n","!ls\n","%cd ../../../../../../../"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/\n","/root/.local/lib/python3.6/site-packages/tensorflow_core/python/keras\n","activations.py\t   estimator\t\t\t   optimizers.py\n","api\t\t   initializers.py\t\t   optimizer_v2\n","applications\t   __init__.py\t\t\t   premade\n","backend_config.py  keras_parameterized.py\t   preprocessing\n","backend.py\t   layers\t\t\t   __pycache__\n","callbacks.py\t   losses.py\t\t\t   regularizers.py\n","callbacks_v1.py    metrics.py\t\t\t   saving\n","constraints.py\t   mixed_precision\t\t   testing_utils.py\n","datasets\t   models.py\t\t\t   utils\n","distribute\t   model_subclassing_test_util.py  wrappers\n","engine\t\t   ops.py\n","/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BtsjtHHT__Bc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R3NuDVJVl-NU","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","import os\n","from time import gmtime, strftime\n","\n","from keras_retinanet import models\n","from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n","from keras_retinanet.utils.visualization import draw_box, draw_caption\n","from keras_retinanet.utils.colors import label_color\n","\n","RANDOM_SEED = 42\n","\n","np.random.seed(RANDOM_SEED)\n","tf.random.set_seed(RANDOM_SEED)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Thr35xgMuZx_","colab_type":"code","colab":{}},"source":["!ls\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J8LEtNbNn7Ri"},"source":["# Training\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A-DO3mGwqq0i","colab":{}},"source":["PRETRAINED_RES50_VANILLA = './snapshots/resnet50_vanilla.h5'\n","PRETRAINED_RES152_VANILLA = './snapshots/resnet152_vanilla_oid.h5'\n","PRETRAINED_MODEL_WI = '../content/drive/My\\ Drive/person_detection/keras-retinanet/snapshots/17-04-2020_07465_resnet50_08_1.h5'\n","logdir = '../content/drive/My\\ Drive/person_detection/keras-retinanet/tensorboard/{}_2'.format(strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NR2UdMesqoMN","outputId":"6c5d3cd3-d610-4527-8ba1-4e16a794366e","executionInfo":{"status":"ok","timestamp":1587001550457,"user_tz":-120,"elapsed":18132882,"user":{"displayName":"horst hammer","photoUrl":"","userId":"16387219538505432860"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%cd ../keras-retinanet/\n","\n","!python keras_retinanet/bin/train.py  --backbone 'vgg19'\\\n","                                      --lr 1e-3\\\n","                                      --batch-size 2\\\n","                                      --steps 2000 \\\n","                                      --epochs 40 \\\n","                                      --weighted-average \\\n","                                      --tensorboard-dir {logdir}\\\n","                                      --filtered-above 0\\\n","                                      --compute-val-loss\\\n","                                      --num-classes 1\\\n","                                      --num-trainer 2\\\n","                                      csv ./annotations/annotations_train.csv ./annotations/classes_filtered.csv \\\n","                                      --val-annotations ./annotations/annotations_test.csv \\\n","                                      # --random-transform\\\n","                                      # --augmentation-factor 0.1\\\n","                                      # --visual-aug-factor 0.3\\\n","                                      # --config config.ini\\\n","                                      # --random-transform \\\n","%cd ../../../../../"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/keras-retinanet\n","Using TensorFlow backend.\n","2020-04-20 08:07:31.773461: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2020-04-20 08:07:31.773612: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2020-04-20 08:07:31.773657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","keras_retinanet/bin/train.py:436: UserWarning: Using experimental backbone vgg19. Only resnet50 has been properly tested.\n","  warnings.warn('Using experimental backbone {}. Only resnet50 has been properly tested.'.format(parsed_args.backbone))\n","./annotations/annotations_test.csv\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 3s 0us/step\n","Creating model, this may take a second...\n","2020-04-20 08:07:39.091722: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n","array([[-22.627417, -11.313708,  22.627417,  11.313708],\n","       [-28.50876 , -14.25438 ,  28.50876 ,  14.25438 ],\n","       [-35.918785, -17.959393,  35.918785,  17.959393],\n","       [-16.      , -16.      ,  16.      ,  16.      ],\n","       [-20.158737, -20.158737,  20.158737,  20.158737],\n","       [-25.398417, -25.398417,  25.398417,  25.398417],\n","       [-11.313708, -22.627417,  11.313708,  22.627417],\n","       [-14.25438 , -28.50876 ,  14.25438 ,  28.50876 ],\n","       [-17.959393, -35.918785,  17.959393,  35.918785]], dtype=float32)> anchors\n","tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n","array([[-45.254833, -22.627417,  45.254833,  22.627417],\n","       [-57.01752 , -28.50876 ,  57.01752 ,  28.50876 ],\n","       [-71.83757 , -35.918785,  71.83757 ,  35.918785],\n","       [-32.      , -32.      ,  32.      ,  32.      ],\n","       [-40.317474, -40.317474,  40.317474,  40.317474],\n","       [-50.796833, -50.796833,  50.796833,  50.796833],\n","       [-22.627417, -45.254833,  22.627417,  45.254833],\n","       [-28.50876 , -57.01752 ,  28.50876 ,  57.01752 ],\n","       [-35.918785, -71.83757 ,  35.918785,  71.83757 ]], dtype=float32)> anchors\n","tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n","array([[ -90.50967 ,  -45.254833,   90.50967 ,   45.254833],\n","       [-114.03504 ,  -57.01752 ,  114.03504 ,   57.01752 ],\n","       [-143.67514 ,  -71.83757 ,  143.67514 ,   71.83757 ],\n","       [ -64.      ,  -64.      ,   64.      ,   64.      ],\n","       [ -80.63495 ,  -80.63495 ,   80.63495 ,   80.63495 ],\n","       [-101.593666, -101.593666,  101.593666,  101.593666],\n","       [ -45.254833,  -90.50967 ,   45.254833,   90.50967 ],\n","       [ -57.01752 , -114.03504 ,   57.01752 ,  114.03504 ],\n","       [ -71.83757 , -143.67514 ,   71.83757 ,  143.67514 ]],\n","      dtype=float32)> anchors\n","tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n","array([[-181.01933,  -90.50967,  181.01933,   90.50967],\n","       [-228.07008, -114.03504,  228.07008,  114.03504],\n","       [-287.35028, -143.67514,  287.35028,  143.67514],\n","       [-128.     , -128.     ,  128.     ,  128.     ],\n","       [-161.2699 , -161.2699 ,  161.2699 ,  161.2699 ],\n","       [-203.18733, -203.18733,  203.18733,  203.18733],\n","       [ -90.50967, -181.01933,   90.50967,  181.01933],\n","       [-114.03504, -228.07008,  114.03504,  228.07008],\n","       [-143.67514, -287.35028,  143.67514,  287.35028]], dtype=float32)> anchors\n","tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n","array([[-362.03867, -181.01933,  362.03867,  181.01933],\n","       [-456.14017, -228.07008,  456.14017,  228.07008],\n","       [-574.70056, -287.35028,  574.70056,  287.35028],\n","       [-256.     , -256.     ,  256.     ,  256.     ],\n","       [-322.5398 , -322.5398 ,  322.5398 ,  322.5398 ],\n","       [-406.37466, -406.37466,  406.37466,  406.37466],\n","       [-181.01933, -362.03867,  181.01933,  362.03867],\n","       [-228.07008, -456.14017,  228.07008,  456.14017],\n","       [-287.35028, -574.70056,  287.35028,  574.70056]], dtype=float32)> anchors\n","Model: \"retinanet\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, None, 3 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, None, None, 6 1792        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, None, None, 6 36928       block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, None, None, 6 0           block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block2_conv1 (Conv2D)           (None, None, None, 1 73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","block2_conv2 (Conv2D)           (None, None, None, 1 147584      block2_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv1 (Conv2D)           (None, None, None, 2 295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","block3_conv2 (Conv2D)           (None, None, None, 2 590080      block3_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv3 (Conv2D)           (None, None, None, 2 590080      block3_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv4 (Conv2D)           (None, None, None, 2 590080      block3_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_conv4[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv1 (Conv2D)           (None, None, None, 5 1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","block4_conv2 (Conv2D)           (None, None, None, 5 2359808     block4_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv3 (Conv2D)           (None, None, None, 5 2359808     block4_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv4 (Conv2D)           (None, None, None, 5 2359808     block4_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, None, None, 5 0           block4_conv4[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv1 (Conv2D)           (None, None, None, 5 2359808     block4_pool[0][0]                \n","__________________________________________________________________________________________________\n","block5_conv2 (Conv2D)           (None, None, None, 5 2359808     block5_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv3 (Conv2D)           (None, None, None, 5 2359808     block5_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv4 (Conv2D)           (None, None, None, 5 2359808     block5_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block5_pool (MaxPooling2D)      (None, None, None, 5 0           block5_conv4[0][0]               \n","__________________________________________________________________________________________________\n","C5_reduced (Conv2D)             (None, None, None, 2 131328      block5_pool[0][0]                \n","__________________________________________________________________________________________________\n","P5_upsampled (UpsampleLike)     (None, None, None, 2 0           C5_reduced[0][0]                 \n","                                                                 block4_pool[0][0]                \n","__________________________________________________________________________________________________\n","C4_reduced (Conv2D)             (None, None, None, 2 131328      block4_pool[0][0]                \n","__________________________________________________________________________________________________\n","P4_merged (Add)                 (None, None, None, 2 0           P5_upsampled[0][0]               \n","                                                                 C4_reduced[0][0]                 \n","__________________________________________________________________________________________________\n","P4_upsampled (UpsampleLike)     (None, None, None, 2 0           P4_merged[0][0]                  \n","                                                                 block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","C3_reduced (Conv2D)             (None, None, None, 2 65792       block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","P6 (Conv2D)                     (None, None, None, 2 1179904     block5_pool[0][0]                \n","__________________________________________________________________________________________________\n","P3_merged (Add)                 (None, None, None, 2 0           P4_upsampled[0][0]               \n","                                                                 C3_reduced[0][0]                 \n","__________________________________________________________________________________________________\n","C6_relu (Activation)            (None, None, None, 2 0           P6[0][0]                         \n","__________________________________________________________________________________________________\n","P3 (Conv2D)                     (None, None, None, 2 590080      P3_merged[0][0]                  \n","__________________________________________________________________________________________________\n","P4 (Conv2D)                     (None, None, None, 2 590080      P4_merged[0][0]                  \n","__________________________________________________________________________________________________\n","P5 (Conv2D)                     (None, None, None, 2 590080      C5_reduced[0][0]                 \n","__________________________________________________________________________________________________\n","P7 (Conv2D)                     (None, None, None, 2 590080      C6_relu[0][0]                    \n","__________________________________________________________________________________________________\n","regression_submodel (Model)     (None, None, 4)      2443300     P3[0][0]                         \n","                                                                 P4[0][0]                         \n","                                                                 P5[0][0]                         \n","                                                                 P6[0][0]                         \n","                                                                 P7[0][0]                         \n","__________________________________________________________________________________________________\n","classification_submodel (Model) (None, None, 1)      2381065     P3[0][0]                         \n","                                                                 P4[0][0]                         \n","                                                                 P5[0][0]                         \n","                                                                 P6[0][0]                         \n","                                                                 P7[0][0]                         \n","__________________________________________________________________________________________________\n","regression (Concatenate)        (None, None, 4)      0           regression_submodel[1][0]        \n","                                                                 regression_submodel[2][0]        \n","                                                                 regression_submodel[3][0]        \n","                                                                 regression_submodel[4][0]        \n","                                                                 regression_submodel[5][0]        \n","__________________________________________________________________________________________________\n","classification (Concatenate)    (None, None, 1)      0           classification_submodel[1][0]    \n","                                                                 classification_submodel[2][0]    \n","                                                                 classification_submodel[3][0]    \n","                                                                 classification_submodel[4][0]    \n","                                                                 classification_submodel[5][0]    \n","==================================================================================================\n","Total params: 28,717,421\n","Trainable params: 28,717,421\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","/usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v2.py:92: UserWarning: The TensorBoard callback `batch_size` argument (for histogram computation) is deprecated with TensorFlow 2.0. It will be ignored.\n","  warnings.warn('The TensorBoard callback `batch_size` argument '\n","Time now and foldername in Tensorboard:  20-04-2020_08740\n","Epoch 1/40\n","2000/2000 [==============================] - 1983s 991ms/step - loss: 3.2142 - regression_loss: 2.4508 - classification_loss: 0.7634 - val_loss: 2.2081 - val_regression_loss: 2.0261 - val_classification_loss: 0.4030\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:04:10 Time:  0:04:10\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.1469\n","mAP: 0.1469\n","\n","Epoch 00001: mAP improved from -inf to 0.14694, saving model to ./snapshots/20-04-2020_08740_vgg19_01_2.h5\n","Epoch 2/40\n","2000/2000 [==============================] - 1449s 724ms/step - loss: 2.2088 - regression_loss: 1.8381 - classification_loss: 0.3708 - val_loss: 1.5961 - val_regression_loss: 1.6978 - val_classification_loss: 0.3170\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:56 Time:  0:01:56\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.3396\n","mAP: 0.3396\n","\n","Epoch 00002: mAP improved from 0.14694 to 0.33964, saving model to ./snapshots/20-04-2020_08740_vgg19_02_2.h5\n","Epoch 3/40\n","2000/2000 [==============================] - 1250s 625ms/step - loss: 2.0094 - regression_loss: 1.6916 - classification_loss: 0.3177 - val_loss: 1.5289 - val_regression_loss: 1.6172 - val_classification_loss: 0.2927\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:57 Time:  0:01:57\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4146\n","mAP: 0.4146\n","\n","Epoch 00003: mAP improved from 0.33964 to 0.41461, saving model to ./snapshots/20-04-2020_08740_vgg19_03_2.h5\n","Epoch 4/40\n","2000/2000 [==============================] - 1240s 620ms/step - loss: 1.9130 - regression_loss: 1.6172 - classification_loss: 0.2958 - val_loss: 1.5572 - val_regression_loss: 1.5752 - val_classification_loss: 0.2802\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:56 Time:  0:01:56\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.3971\n","mAP: 0.3971\n","\n","Epoch 00004: mAP did not improve from 0.41461\n","Epoch 5/40\n","2000/2000 [==============================] - 1233s 617ms/step - loss: 1.8716 - regression_loss: 1.5837 - classification_loss: 0.2879 - val_loss: 1.4922 - val_regression_loss: 1.5671 - val_classification_loss: 0.2821\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:57 Time:  0:01:57\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.3862\n","mAP: 0.3862\n","\n","Epoch 00005: mAP did not improve from 0.41461\n","Epoch 6/40\n","2000/2000 [==============================] - 1240s 620ms/step - loss: 1.8499 - regression_loss: 1.5733 - classification_loss: 0.2766 - val_loss: 1.4550 - val_regression_loss: 1.5583 - val_classification_loss: 0.2722\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:58 Time:  0:01:58\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4188\n","mAP: 0.4188\n","\n","Epoch 00006: mAP improved from 0.41461 to 0.41876, saving model to ./snapshots/20-04-2020_08740_vgg19_06_2.h5\n","Epoch 7/40\n","2000/2000 [==============================] - 1237s 619ms/step - loss: 1.8259 - regression_loss: 1.5553 - classification_loss: 0.2705 - val_loss: 1.4731 - val_regression_loss: 1.5303 - val_classification_loss: 0.2659\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:56 Time:  0:01:56\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4838\n","mAP: 0.4838\n","\n","Epoch 00007: mAP improved from 0.41876 to 0.48383, saving model to ./snapshots/20-04-2020_08740_vgg19_07_2.h5\n","Epoch 8/40\n","2000/2000 [==============================] - 1245s 623ms/step - loss: 1.8166 - regression_loss: 1.5466 - classification_loss: 0.2701 - val_loss: 1.4130 - val_regression_loss: 1.5320 - val_classification_loss: 0.2737\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:58 Time:  0:01:58\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4500\n","mAP: 0.4500\n","\n","Epoch 00008: mAP did not improve from 0.48383\n","Epoch 9/40\n","2000/2000 [==============================] - 1243s 621ms/step - loss: 1.7927 - regression_loss: 1.5290 - classification_loss: 0.2637 - val_loss: 1.5134 - val_regression_loss: 1.5437 - val_classification_loss: 0.2733\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:57 Time:  0:01:57\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4851\n","mAP: 0.4851\n","\n","Epoch 00009: mAP improved from 0.48383 to 0.48511, saving model to ./snapshots/20-04-2020_08740_vgg19_09_2.h5\n","Epoch 10/40\n","2000/2000 [==============================] - 1245s 622ms/step - loss: 1.8161 - regression_loss: 1.5455 - classification_loss: 0.2706 - val_loss: 1.3602 - val_regression_loss: 1.5476 - val_classification_loss: 0.2815\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:58 Time:  0:01:58\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4819\n","mAP: 0.4819\n","\n","Epoch 00010: mAP did not improve from 0.48511\n","Epoch 11/40\n","2000/2000 [==============================] - 1249s 625ms/step - loss: 1.7908 - regression_loss: 1.5278 - classification_loss: 0.2630 - val_loss: 1.3250 - val_regression_loss: 1.5179 - val_classification_loss: 0.2678\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:57 Time:  0:01:57\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4852\n","mAP: 0.4852\n","\n","Epoch 00011: mAP improved from 0.48511 to 0.48524, saving model to ./snapshots/20-04-2020_08740_vgg19_11_2.h5\n","Epoch 12/40\n","2000/2000 [==============================] - 1245s 622ms/step - loss: 1.8100 - regression_loss: 1.5433 - classification_loss: 0.2667 - val_loss: 1.4342 - val_regression_loss: 1.5395 - val_classification_loss: 0.2688\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:56 Time:  0:01:56\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4232\n","mAP: 0.4232\n","\n","Epoch 00012: mAP did not improve from 0.48524\n","Epoch 13/40\n","2000/2000 [==============================] - 1253s 626ms/step - loss: 1.8019 - regression_loss: 1.5369 - classification_loss: 0.2649 - val_loss: 1.4834 - val_regression_loss: 1.5426 - val_classification_loss: 0.2629\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:58 Time:  0:01:58\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4615\n","mAP: 0.4615\n","\n","Epoch 00013: mAP did not improve from 0.48524\n","\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 14/40\n","2000/2000 [==============================] - 1241s 621ms/step - loss: 1.6671 - regression_loss: 1.4290 - classification_loss: 0.2381 - val_loss: 1.2903 - val_regression_loss: 1.4154 - val_classification_loss: 0.2358\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:58 Time:  0:01:58\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.5023\n","mAP: 0.5023\n","\n","Epoch 00014: mAP improved from 0.48524 to 0.50235, saving model to ./snapshots/20-04-2020_08740_vgg19_14_2.h5\n","Epoch 15/40\n","2000/2000 [==============================] - 1236s 618ms/step - loss: 1.6208 - regression_loss: 1.3937 - classification_loss: 0.2271 - val_loss: 1.2603 - val_regression_loss: 1.3955 - val_classification_loss: 0.2338\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:56 Time:  0:01:56\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.4902\n","mAP: 0.4902\n","\n","Epoch 00015: mAP did not improve from 0.50235\n","Epoch 16/40\n","2000/2000 [==============================] - 1220s 610ms/step - loss: 1.5916 - regression_loss: 1.3688 - classification_loss: 0.2228 - val_loss: 1.2742 - val_regression_loss: 1.3888 - val_classification_loss: 0.2313\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:57 Time:  0:01:57\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.5189\n","mAP: 0.5189\n","\n","Epoch 00016: mAP improved from 0.50235 to 0.51891, saving model to ./snapshots/20-04-2020_08740_vgg19_16_2.h5\n","Epoch 17/40\n","2000/2000 [==============================] - 1220s 610ms/step - loss: 1.5915 - regression_loss: 1.3679 - classification_loss: 0.2236 - val_loss: 1.2007 - val_regression_loss: 1.3823 - val_classification_loss: 0.2304\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:54 Time:  0:01:54\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.5187\n","mAP: 0.5187\n","\n","Epoch 00017: mAP did not improve from 0.51891\n","Epoch 18/40\n","2000/2000 [==============================] - 1227s 614ms/step - loss: 1.5784 - regression_loss: 1.3575 - classification_loss: 0.2209 - val_loss: 1.2030 - val_regression_loss: 1.3704 - val_classification_loss: 0.2276\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:55 Time:  0:01:55\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.5069\n","mAP: 0.5069\n","\n","Epoch 00018: mAP did not improve from 0.51891\n","Epoch 19/40\n","2000/2000 [==============================] - 1233s 617ms/step - loss: 1.5644 - regression_loss: 1.3459 - classification_loss: 0.2185 - val_loss: 1.2111 - val_regression_loss: 1.3647 - val_classification_loss: 0.2275\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:56 Time:  0:01:56\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.5289\n","mAP: 0.5289\n","\n","Epoch 00019: mAP improved from 0.51891 to 0.52887, saving model to ./snapshots/20-04-2020_08740_vgg19_19_2.h5\n","Epoch 20/40\n","2000/2000 [==============================] - 1212s 606ms/step - loss: 1.5610 - regression_loss: 1.3432 - classification_loss: 0.2178 - val_loss: 1.1914 - val_regression_loss: 1.3642 - val_classification_loss: 0.2273\n","Running network: 100% (897 of 897) |######| Elapsed Time: 0:01:52 Time:  0:01:52\n","Parsing annotations: 100% (897 of 897) |##| Elapsed Time: 0:00:00 Time:  0:00:00\n","24978 instances of class pedestrian with average precision: 0.5125\n","mAP: 0.5125\n","\n","Epoch 00020: mAP did not improve from 0.52887\n","Epoch 21/40\n","1885/2000 [===========================>..] - ETA: 1:01 - loss: 1.5375 - regression_loss: 1.3228 - classification_loss: 0.2148"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MdEIYFDntAzw"},"source":["## Debugging"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PKacEUM2tAOw","colab":{}},"source":["%cd /content/drive/My Drive/person_detection/keras-retinanet\n","!python keras_retinanet/bin/debug.py --annotations \\\n","                                     --anchors \\\n","                                     --no-gui \\\n","                                     csv annot_train.csv classes.csv\n","%cd ../../../../.."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F5VvYnzrdc2k"},"source":["### Anchor Optimization"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9gHzgY2kxk9G","outputId":"f4aafb9f-bb23-47df-a9b1-d19041653586","executionInfo":{"status":"ok","timestamp":1586854422269,"user_tz":-120,"elapsed":188615,"user":{"displayName":"horst hammer","photoUrl":"","userId":"16387219538505432860"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%cd /content/drive/My Drive/person_detection\n","!git clone https://github.com/martinzlocha/anchor-optimization.git\n","%cd anchor-optimization\n","!pip install .\n","!python setup.py build_ext --inplace"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/person_detection\n","fatal: destination path 'anchor-optimization' already exists and is not an empty directory.\n","/content/drive/My Drive/person_detection/anchor-optimization\n","Processing /content/drive/My Drive/person_detection/anchor-optimization\n","Requirement already satisfied: keras_retinanet==0.5.1 in /usr/local/lib/python3.6/dist-packages (from anchor-optimization==0.0.1) (0.5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from anchor-optimization==0.0.1) (1.18.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from anchor-optimization==0.0.1) (1.4.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from anchor-optimization==0.0.1) (0.29.16)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from anchor-optimization==0.0.1) (2.2.0rc2)\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from keras_retinanet==0.5.1->anchor-optimization==0.0.1) (3.38.0)\n","Requirement already satisfied: keras-resnet==0.1.0 in /usr/local/lib/python3.6/dist-packages (from keras_retinanet==0.5.1->anchor-optimization==0.0.1) (0.1.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_retinanet==0.5.1->anchor-optimization==0.0.1) (2.3.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from keras_retinanet==0.5.1->anchor-optimization==0.0.1) (7.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras_retinanet==0.5.1->anchor-optimization==0.0.1) (1.12.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from keras_retinanet==0.5.1->anchor-optimization==0.0.1) (4.1.2.30)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (0.2.0)\n","Collecting gast==0.3.3\n","  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (3.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (1.1.0)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (2.10.0)\n","Collecting tensorflow-estimator<2.3.0,>=2.2.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/a1/43056b25b933cd817d383dc04282bdc460d91f6f44faf1e3b6ec7d990d43/tensorflow_estimator-2.2.0rc0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (1.12.1)\n","Collecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/f5/d75a6f7935e4a4870d85770bc9976b12e7024fbceb83a1a6bc50e6deb7c4/tensorboard-2.2.0-py3-none-any.whl (2.8MB)\n","\u001b[K     |████████████████████████████████| 2.8MB 42.9MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (0.34.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (1.28.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (0.9.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->anchor-optimization==0.0.1) (3.2.0)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->keras_retinanet==0.5.1->anchor-optimization==0.0.1) (2.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras_retinanet==0.5.1->anchor-optimization==0.0.1) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras_retinanet==0.5.1->anchor-optimization==0.0.1) (1.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow->anchor-optimization==0.0.1) (46.1.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (3.2.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (2.21.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (1.6.0.post3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (1.7.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (0.4.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (2020.4.5.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (2.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (0.2.8)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (3.1.1)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (4.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->anchor-optimization==0.0.1) (3.1.0)\n","Building wheels for collected packages: anchor-optimization\n","  Building wheel for anchor-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for anchor-optimization: filename=anchor_optimization-0.0.1-cp36-cp36m-linux_x86_64.whl size=77469 sha256=c84b6f9678effe26a27d3d9e8296e67e304b0982fe9f78e98822f8b58f0f7cb3\n","  Stored in directory: /root/.cache/pip/wheels/2f/43/fd/0988710ca80b1886cd214735a7b0dc9c39e4151e1be7d4b4b2\n","Successfully built anchor-optimization\n","\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 2.2.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 2.2.0rc0 which is incompatible.\u001b[0m\n","Installing collected packages: anchor-optimization, gast, tensorflow-estimator, tensorboard\n","  Found existing installation: gast 0.2.2\n","    Uninstalling gast-0.2.2:\n","      Successfully uninstalled gast-0.2.2\n","  Found existing installation: tensorflow-estimator 2.1.0\n","    Uninstalling tensorflow-estimator-2.1.0:\n","      Successfully uninstalled tensorflow-estimator-2.1.0\n","  Found existing installation: tensorboard 2.1.1\n","    Uninstalling tensorboard-2.1.1:\n","      Successfully uninstalled tensorboard-2.1.1\n","Successfully installed anchor-optimization-0.0.1 gast-0.3.3 tensorboard-2.2.0 tensorflow-estimator-2.2.0rc0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","tensorboard","tensorflow_estimator"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["running build_ext\n","skipping 'compute_overlap.c' Cython extension (up-to-date)\n","copying build/lib.linux-x86_64-3.6/compute_overlap.cpython-36m-x86_64-linux-gnu.so -> \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TK9l1MUuenkr","outputId":"0e109b5b-12d4-4ae3-d340-0a29cd9d791b","executionInfo":{"status":"ok","timestamp":1586864721369,"user_tz":-120,"elapsed":10135046,"user":{"displayName":"horst hammer","photoUrl":"","userId":"16387219538505432860"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install tensorflow-gpu==1.15\n","!python ./../anchor-optimization/optimize_anchors.py ./../keras-retinanet/annotations/annotations_train.csv\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-gpu==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.18.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.10.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.0.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.28.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.2.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.34.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.9.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15) (46.1.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.2.1)\n","Using TensorFlow backend.\n","Loading object dimensions.\n","Optimising anchors.\n","Current best anchor configuration\n","Ratios: [0.303, 1.0, 3.305]\n","Scales: [0.678, 1.021, 1.531]\n","Number of labels that don't have any matching anchor: 3811\n","\n","Current best anchor configuration\n","Ratios: [0.351, 1.0, 2.848]\n","Scales: [0.525, 0.539, 1.592]\n","Number of labels that don't have any matching anchor: 1457\n","\n","Current best anchor configuration\n","Ratios: [0.386, 1.0, 2.591]\n","Scales: [0.436, 0.863, 1.133]\n","Number of labels that don't have any matching anchor: 813\n","\n","Current best anchor configuration\n","Ratios: [0.361, 1.0, 2.767]\n","Scales: [0.46, 0.804, 1.147]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.417, 1.0, 2.401]\n","Scales: [0.41, 0.973, 1.345]\n","Number of labels that don't have any matching anchor: 764\n","\n","Current best anchor configuration\n","Ratios: [0.426, 1.0, 2.348]\n","Scales: [0.427, 0.674, 1.177]\n","Number of labels that don't have any matching anchor: 915\n","\n","Current best anchor configuration\n","Ratios: [0.426, 1.0, 2.35]\n","Scales: [0.46, 0.674, 1.147]\n","Number of labels that don't have any matching anchor: 1088\n","\n","Current best anchor configuration\n","Ratios: [0.467, 1.0, 2.142]\n","Scales: [0.422, 0.536, 1.343]\n","Number of labels that don't have any matching anchor: 1047\n","\n","Current best anchor configuration\n","Ratios: [0.477, 1.0, 2.098]\n","Scales: [0.417, 0.532, 0.67]\n","Number of labels that don't have any matching anchor: 1127\n","\n","Current best anchor configuration\n","Ratios: [0.455, 1.0, 2.2]\n","Scales: [0.405, 0.532, 0.67]\n","Number of labels that don't have any matching anchor: 957\n","\n","Current best anchor configuration\n","Ratios: [0.444, 1.0, 2.255]\n","Scales: [0.407, 0.529, 0.642]\n","Number of labels that don't have any matching anchor: 968\n","\n","Current best anchor configuration\n","Ratios: [0.425, 1.0, 2.353]\n","Scales: [0.402, 0.531, 0.68]\n","Number of labels that don't have any matching anchor: 835\n","\n","Current best anchor configuration\n","Ratios: [0.421, 1.0, 2.376]\n","Scales: [0.428, 0.54, 0.684]\n","Number of labels that don't have any matching anchor: 954\n","\n","Current best anchor configuration\n","Ratios: [0.427, 1.0, 2.34]\n","Scales: [0.414, 0.531, 0.68]\n","Number of labels that don't have any matching anchor: 889\n","\n","Current best anchor configuration\n","Ratios: [0.422, 1.0, 2.368]\n","Scales: [0.412, 0.527, 0.663]\n","Number of labels that don't have any matching anchor: 872\n","\n","Current best anchor configuration\n","Ratios: [0.425, 1.0, 2.353]\n","Scales: [0.41, 0.523, 0.664]\n","Number of labels that don't have any matching anchor: 879\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.308]\n","Scales: [0.404, 0.512, 0.659]\n","Number of labels that don't have any matching anchor: 892\n","\n","Current best anchor configuration\n","Ratios: [0.422, 1.0, 2.368]\n","Scales: [0.401, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 863\n","\n","Current best anchor configuration\n","Ratios: [0.427, 1.0, 2.342]\n","Scales: [0.412, 0.523, 0.663]\n","Number of labels that don't have any matching anchor: 896\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.318]\n","Scales: [0.403, 0.509, 0.655]\n","Number of labels that don't have any matching anchor: 887\n","\n","Current best anchor configuration\n","Ratios: [0.432, 1.0, 2.313]\n","Scales: [0.405, 0.513, 0.657]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.427, 1.0, 2.343]\n","Scales: [0.4, 0.505, 0.645]\n","Number of labels that don't have any matching anchor: 878\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.31]\n","Scales: [0.402, 0.508, 0.649]\n","Number of labels that don't have any matching anchor: 908\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.31]\n","Scales: [0.402, 0.508, 0.649]\n","Number of labels that don't have any matching anchor: 908\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.31]\n","Scales: [0.402, 0.508, 0.649]\n","Number of labels that don't have any matching anchor: 908\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.311]\n","Scales: [0.4, 0.511, 0.647]\n","Number of labels that don't have any matching anchor: 899\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.311]\n","Scales: [0.4, 0.511, 0.647]\n","Number of labels that don't have any matching anchor: 899\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.311]\n","Scales: [0.4, 0.511, 0.647]\n","Number of labels that don't have any matching anchor: 899\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.311]\n","Scales: [0.4, 0.511, 0.647]\n","Number of labels that don't have any matching anchor: 899\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.311]\n","Scales: [0.401, 0.51, 0.648]\n","Number of labels that don't have any matching anchor: 907\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.311]\n","Scales: [0.401, 0.51, 0.648]\n","Number of labels that don't have any matching anchor: 907\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.311]\n","Scales: [0.401, 0.51, 0.648]\n","Number of labels that don't have any matching anchor: 906\n","\n","Current best anchor configuration\n","Ratios: [0.433, 1.0, 2.311]\n","Scales: [0.401, 0.51, 0.648]\n","Number of labels that don't have any matching anchor: 906\n","\n","Current best anchor configuration\n","Ratios: [0.432, 1.0, 2.313]\n","Scales: [0.401, 0.509, 0.647]\n","Number of labels that don't have any matching anchor: 907\n","\n","Current best anchor configuration\n","Ratios: [0.432, 1.0, 2.313]\n","Scales: [0.401, 0.509, 0.647]\n","Number of labels that don't have any matching anchor: 907\n","\n","Current best anchor configuration\n","Ratios: [0.432, 1.0, 2.315]\n","Scales: [0.401, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 904\n","\n","Current best anchor configuration\n","Ratios: [0.432, 1.0, 2.315]\n","Scales: [0.401, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 904\n","\n","Current best anchor configuration\n","Ratios: [0.432, 1.0, 2.315]\n","Scales: [0.401, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 904\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.318]\n","Scales: [0.4, 0.507, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.318]\n","Scales: [0.4, 0.507, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.318]\n","Scales: [0.4, 0.507, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.318]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.318]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.318]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.318]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.319]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.319]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.319]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 893\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.32]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 891\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.32]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 891\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.32]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 891\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.321]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 890\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.321]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 890\n","\n","Current best anchor configuration\n","Ratios: [0.431, 1.0, 2.321]\n","Scales: [0.4, 0.508, 0.645]\n","Number of labels that don't have any matching anchor: 890\n","\n","Current best anchor configuration\n","Ratios: [0.43, 1.0, 2.323]\n","Scales: [0.4, 0.509, 0.646]\n","Number of labels that don't have any matching anchor: 888\n","\n","Current best anchor configuration\n","Ratios: [0.43, 1.0, 2.323]\n","Scales: [0.4, 0.509, 0.646]\n","Number of labels that don't have any matching anchor: 888\n","\n","Current best anchor configuration\n","Ratios: [0.43, 1.0, 2.324]\n","Scales: [0.4, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 888\n","\n","Current best anchor configuration\n","Ratios: [0.43, 1.0, 2.324]\n","Scales: [0.4, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 888\n","\n","Current best anchor configuration\n","Ratios: [0.43, 1.0, 2.324]\n","Scales: [0.4, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 888\n","\n","Current best anchor configuration\n","Ratios: [0.43, 1.0, 2.324]\n","Scales: [0.4, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 888\n","\n","Current best anchor configuration\n","Ratios: [0.43, 1.0, 2.324]\n","Scales: [0.4, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 888\n","\n","Current best anchor configuration\n","Ratios: [0.43, 1.0, 2.324]\n","Scales: [0.4, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 888\n","\n","Current best anchor configuration\n","Ratios: [0.43, 1.0, 2.324]\n","Scales: [0.4, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 888\n","\n","Optimization ended successfully!\n","\n","Final best anchor configuration\n","Ratios: [0.43, 1.0, 2.324]\n","Scales: [0.4, 0.508, 0.646]\n","Number of labels that don't have any matching anchor: 888\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dqmpr6FOZ3k4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kbPa5TKZucf","colab_type":"code","outputId":"95d927c8-a270-4681-9fe2-21bf5954674f","executionInfo":{"status":"ok","timestamp":1586275768637,"user_tz":-120,"elapsed":1035,"user":{"displayName":"horst hammer","photoUrl":"","userId":"16387219538505432860"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/person_detection/keras-retinanet\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MVZOCeiyxZX3"},"source":["## Functions\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BfRvTatDxVrh","colab":{}},"source":["# Generate the classes csv file\n","with open(annotations, newline='', mode='x') as csvfile:\n","  csv_writer = csv.writer(csvfile, delimiter=',')\n","  for filename in os.listdir(images_path)[0:10]:\n","    if str(filename + '.txt') in annot:\n","      f = open(annot_path + '/' +  filename + '.txt', 'r')\n","      \n","      for index, line in enumerate(f): \n","        if index == 0: \n","          if line.strip() == '0':\n","            print('Not any  object in the image!')\n","          continue\n","          \n","        else: \n","          split_line = line[:line.find('/')].split(' ')\n","          first_char = split_line.pop(0)\n","          split_line.insert(len(split_line), first_char)\n","          split_line.insert(0, images_path + '/' + filename)\n","          #convert from index to class label \n","          try:\n","            split_line[-1] = classes_ids[int(split_line[-1])]\n","          except: \n","            continue\n","          split_line[0] = split_line[0]\n","\n","          csv_writer.writerow(split_line)\n","      \n","      f.close()\n","\n","#create indexing csv file\n","with open('classes.csv', newline='', mode='x') as csvfile:\n","  csv_writer = csv.writer(csvfile, delimiter=',')\n","  for index, key in enumerate(classes_ids.keys()):\n","    csv_writer.writerow([str(classes_ids[key]), index])\n","\n","\n","#Check for wrongly annotaded bounding boxes\n","path = '/content/drive/My Drive/person_detection/keras-retinanet/annotations.csv'\n","def check_bb(path):\n","  colnames = ['filename', 'x1', 'y1', 'x2', 'y2', 'class_label']\n","  df = pd.read_csv(path, names=colnames)\n","  df_new = df.loc[(df.x1 < df.x2) & (df.y1 < df.y2), : ]\n","  print ('Reduces shape from ', df.shape, 'to ', df_new.shape)\n","  return df_new\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SroNj-Q1xWmu","colab":{}},"source":["def replace_annoation_folder(new_folder, annot_path, old_img_path):\n","  '''Start this function from folder root, otherwise wont work properly'''\n","\n","  df_annot = pd.read_csv(annot_path + '/annotations_pathkeras.csv',\n","                         names=['name', 'x1', 'y1', 'x2', 'y2', 'label'])\n","  df_annot = df_annot.reset_index().drop(0).drop(columns='index')\n","  df_annot['name'] = df_annot['name'].str.replace(old_img_path, new_folder)\n","  df_annot = df_annot.dropna()\n","  df_annot.to_csv(annot_path + '/annotations_new.csv',\n","                  index=None, header=None)\n","  return\n","\n","\n","old_folder = '/content/drive/My Drive/PersonDetection/WiderPerson/Images'\n","new_folder = '/content/drive/My Drive/person_detection/WiderPerson/Images'\n","annot_path_csv = '/content/drive/My Drive/person_detection/keras-retinanet'\n","replace_annoation_folder(new_folder, annot_path_csv, old_folder)\n"],"execution_count":0,"outputs":[]}]}