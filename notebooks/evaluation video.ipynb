{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluation video.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1BIKSaWDTJxvmbJZ1PtfvWelVpQym1Prm","authorship_tag":"ABX9TyP4dRGZdvoye/ag8BHp5HiR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"44HMfawIw58z","colab_type":"code","colab":{}},"source":["!pip install --upgrade keras\n","!pip install gdown\n","!pip install tensorflow-gpu==1.15"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yy5Gppkug1B4","colab_type":"code","colab":{}},"source":["%cd ../../../../../../\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uxiK19ItuL7x","colab_type":"code","colab":{}},"source":["!git clone https://Yannick947:Amadeusieben7@github.com/Yannick947/keras-retinanet.git\n","%cd keras-retinanet/\n","!pip install .\n","!python setup.py build_ext --inplace\n","%cd ../../../"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogyVuGKwtxB4","colab_type":"code","colab":{}},"source":["import keras\n","from keras_retinanet import models\n","from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n","from keras_retinanet.utils.visualization import draw_box, draw_caption\n","from keras_retinanet.utils.colors import label_color\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import numpy as np\n","import time\n","from google.colab.patches import cv2_imshow\n","import tensorflow as tf\n","import pandas as pd\n","\n","def get_session():\n","    config = tf.compat.v1.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    return tf.compat.v1.Session(config=config)\n","\n","keras.backend.tensorflow_backend.set_session(get_session())\n","\n","model_path_vanilla = '/content/drive/My Drive/person_detection/keras-retinanet/snapshots/resnet50_vanilla.h5'\n","model_path_custom = '/content/drive/My Drive/person_detection/keras-retinanet/snapshots/17-04-2020_07465_resnet50_08_1.h5'\n","\n","model = models.load_model(model_path_vanilla, backbone_name='resnet50')\n","# model = models.convert_model(model, nms_threshold=0.3) #comment out if model is already an inference model\n","labels_to_names = {0: 'pedestrian'}                                     \n","\n","video_path_parent = '/content/drive/My Drive/person_detection/bus_video_showcases/'  \n","video_showcases = ['nightly']\n"," \n","fps = 20"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"btyi0ejYiW6j","colab_type":"text"},"source":["# Create csvs for every video and single label file "]},{"cell_type":"code","metadata":{"id":"C1QBNv8ljgSP","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/person_detection/keras-retinanet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oeZPnxYDiWpb","colab_type":"code","colab":{}},"source":["!python -m keras_retinanet.preprocessing_videos.generate_csvs_colab --nms-threshold 0.3\\\n","                                                                    --predict-threshold 0.5\\\n","                                                                    --downscale-factor-y 3\\\n","                                                                    --static-filter\\"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ggD5t0wLS0-L","colab_type":"text"},"source":["# Process csv files\n","\n","- unite label files and move to drive folder for downloading\n","- Move csv files to seperate drive folder for downloading \n"]},{"cell_type":"code","metadata":{"id":"1okHiVkvSz3n","colab_type":"code","colab":{}},"source":["!python -m keras_retinanet.preprocessing_videos.process_labels\n","!python -m keras_retinanet.preprocessing_videos.process_csvs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JpAue5GtoSJr","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"jua7Hr0A72a8","colab_type":"text"},"source":["# Create detected video for single input video"]},{"cell_type":"code","metadata":{"id":"udINCapLtS7h","colab_type":"code","colab":{}},"source":["def run_detection_video(video_path):\n","    frame_index = 0\n","    success = True\n","    start = time.time()\n","\n","    while success:\n","        if frame_index % 100 == 0:\n","            print(\"frame: \", frame_index)\n","        frame_index += 1\n","        # Read next image\n","        success, image = vcapture.read()\n","\n","        if success:\n","\n","            draw = image.copy()\n","            draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n","\n","            image = preprocess_image(image)\n","            image, scale = resize_image(image, min_side=800, max_side=1333)\n","            boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n","            boxes /= scale\n","\n","            for box, score, label in zip(boxes[0], scores[0], labels[0]):\n","                \n","                # if (label != 0): \n","                #     continue\n","                # print(score, label)\n","\n","                # scores are sorted so we can break\n","\n","                if score < THRESH:\n","                    break\n","\n","                color = label_color(label)\n","\n","                b = box.astype(int)\n","                draw_box(draw, b, color=color)\n","                caption = \"{} {:.3f}\".format('Person', score)\n","                draw_caption(draw, b, caption)\n","            detected_frame = cv2.cvtColor(draw, cv2.COLOR_RGB2BGR)\n","            vwriter.write(detected_frame)  # overwrites video slice\n","\n","    vcapture.release()\n","    vwriter.release()\n","    end = time.time()\n","    print(\"Total Time: \", end - start)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNqRqS-DHOzW","colab_type":"code","colab":{}},"source":["%cd ../../../../../\n","THRESH = 0.55\n","for showcase in video_showcases:\n","  video_path = video_path_parent + 'bus_showcase_' + showcase + '.avi'\n","  print(video_path)\n","  output_path = video_path_parent + 'bus_showcase_' + showcase + '_detected.mp4'\n","  vcapture = cv2.VideoCapture(video_path)\n","  width = int(vcapture.get(cv2.CAP_PROP_FRAME_WIDTH))  # uses given video width and height\n","  height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","  vwriter = cv2.VideoWriter(output_path,cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n","  print('width: ', width, 'height: ', height)\n","  num_frames = int(vcapture.get(cv2.CAP_PROP_FRAME_COUNT))\n","  run_detection_video(video_path)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uDIJ1GPV_s2c","colab_type":"text"},"source":["# Delete all csv files in dir\n","### care using, will delete all csv files in given directory"]},{"cell_type":"code","metadata":{"id":"8TpOA7m9_qs7","colab_type":"code","colab":{}},"source":["%cd /content/drive/My\\ Drive/person_detection/keras-retinanet/keras_retinanet/preprocessing_videos\n","parent_dir = '/content/drive/My\\ Drive/person_detection/bus_videos/pcds_dataset/'\n","!python -m remove_csvs $parent_dir"],"execution_count":0,"outputs":[]}]}